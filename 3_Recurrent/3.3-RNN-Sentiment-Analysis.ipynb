{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced by https://github.com/pytorch/tutorials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory RNN\n",
    "\n",
    "This notebook\n",
    "* Introduces the LSTM\n",
    "* Combines what we have seen in the previous two notebooks\n",
    "* Use an LSTM to perform sentiment analysis on SST\n",
    "__\n",
    "\n",
    "\n",
    "\n",
    "## Why does\n",
    "The vanilla RNN has issues with vanishing gradients which give challenges in saving memory over longer sequences.\n",
    "\n",
    "To battle these issues the gated hidden units were create.\n",
    "We have Long Short-Term Memory (LSTM) (see [Christopher Olah's walk through](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)) and Gated Recurrent Unit (GRU) which have shown increased performance in saving and reusing memory in later timesteps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![lstm](../static_files/lstm_cell.png)\n",
    "source: https://arxiv.org/abs/1412.7828\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The LSTM contains three gates, input, forget, output gates and a memory cell.\n",
    "The output of the LSTM unit is computed with the following functions, where $\\sigma = \\mathrm{softmax}$.\n",
    "We have input gate $i$, forget gate $f$, and output gate $o$ defines as\n",
    "\n",
    "- $i = \\sigma ( U^i x_t + W^i h_{t-1})$\n",
    "\n",
    "- $f = \\sigma ( U^f x_t + W^f h_{t-1})$\n",
    "\n",
    "- $o = \\sigma ( U^o x_t + W^o h_{t-1})$\n",
    "\n",
    "where $U^i, U^f, U^o$ are weight matrices applied to $x_t$ (input vector), and\n",
    "$W^i, W^f, W^o$ are weight matrices applied to $h_{t-1}$ (hidden state vector) for each respective gate.\n",
    "\n",
    "$h_{t-1}$, from the previous time step along with the current input $x_t$ are used to compute the a candidate $g$\n",
    "\n",
    "- $g = \\mathrm{tanh}( U^g x_t +  W^g h_{t-1})$\n",
    "\n",
    "The value of the cell's memory, $c_t$, is updated as\n",
    "\n",
    "- $c_t = c_{t-1} \\circ f + g \\circ i$\n",
    "\n",
    "where $c_{t-1}$ is the previous memory, and $\\circ$ refers to element-wise multiplication.\n",
    "\n",
    "The output, $h_t$, is computed as\n",
    "\n",
    "- $h_t = \\mathrm{tanh}(c_t) \\circ o$\n",
    "\n",
    "and it is used for both the timestep's output and the next timestep, whereas $c_t$ is exclusively sent to the next timestep.\n",
    "This makes $c_t$ a memory feature, and is not used directly to compute the output of the timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford sentiment treebank\n",
    "\n",
    "We will continue with the SST.\n",
    "See previous notebook for more information.\n",
    "\n",
    "The code below loads the data, similar to what we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '41c4c2dc-54a8-4b04-8ac5-69515dd4b826' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '41c4c2dc-54a8-4b04-8ac5-69515dd4b826' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.13.0.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.13.0.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.13.0.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"41c4c2dc-54a8-4b04-8ac5-69515dd4b826\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear, RNN, LSTM\n",
    "from torch.nn.functional import softmax, relu\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# we'll use the bokeh library to create beautiful plots\n",
    "# *_notebook functions are needed for correct use in jupyter\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook, show, push_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() and False\n",
    "\n",
    "def get_variable(x):\n",
    "    \"\"\" Converts tensors to cuda, if available. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cuda()\n",
    "    return x\n",
    "\n",
    "def get_numpy(x):\n",
    "    \"\"\" Get numpy array for both cuda and not. \"\"\"\n",
    "    if use_cuda:\n",
    "        return x.cpu().data.numpy()\n",
    "    return x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume that all fields are sequential, i.e. there will be a sequence of data\n",
    "# however, the label field will not contain any sequence\n",
    "TEXT = data.Field(sequential=True)\n",
    "LABEL = data.Field(sequential=False)\n",
    "\n",
    "# create SST dataset splits\n",
    "# note, we remove samples with neutral labels\n",
    "train_set, validation_set, _ = datasets.SST.splits(TEXT,\n",
    "                                                   LABEL,\n",
    "                                                   fine_grained=False,\n",
    "                                                   train_subtrees=True,\n",
    "                                                   filter_pred=lambda ex: ex.label != 'neutral')\n",
    "\n",
    "# build the vocabularies\n",
    "# NOTE you should download the GloVe vocabulary, it is quite large..\n",
    "url = 'https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.simple.vec'\n",
    "TEXT.build_vocab(train_set, max_size=None, vectors=Vectors('wiki.simple.vec', url=url))\n",
    "\n",
    "# TEXT.build_vocab(train_set, max_size=None, vectors=[GloVe(name='840B', dim='300')])\n",
    "LABEL.build_vocab(train_set)\n",
    "# make iterator for splits\n",
    "# device gives a CUDA enabled device (-1 disables it)\n",
    "train_iter, val_iter, _ = data.BucketIterator.splits((train_set, validation_set, _),\n",
    "                                                     batch_size=128, \n",
    "                                                     device=0 if use_cuda else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "We now use an `RNN` to classify the sentences.\n",
    "(You will change this into an LSTM as an exercise).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embeddings): Embedding(18005, 300)\n",
      "  (proj): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (lstm): LSTM(300, 150, bidirectional=True)\n",
      "  (fc_part): Sequential(\n",
      "    (0): Linear(in_features=600, out_features=150, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=150, out_features=3, bias=True)\n",
      "    (7): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# size of embeddings\n",
    "embedding_dim = TEXT.vocab.vectors.size()[1]\n",
    "num_embeddings = TEXT.vocab.vectors.size()[0]\n",
    "num_classes = len(LABEL.vocab.itos)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings, embedding_dim)\n",
    "\n",
    "        # use pretrained embeddings\n",
    "        self.embeddings.weight.data.copy_(TEXT.vocab.vectors)\n",
    "        self.embeddings.weight.detach_()\n",
    "        \n",
    "        self.proj = nn.Linear(\n",
    "            in_features=300,\n",
    "            out_features=300,\n",
    "            bias=True)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=150,\n",
    "            num_layers=1,\n",
    "            bidirectional=True)\n",
    "        \n",
    "        self.fc_part = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=600,\n",
    "                out_features=150,\n",
    "                bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(\n",
    "                in_features=150,\n",
    "                out_features=150,\n",
    "                bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(\n",
    "                in_features=150,\n",
    "                out_features=3,\n",
    "                bias=True),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = {}\n",
    "        # get embeddings\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        x = self.proj(x)\n",
    "        \n",
    "        # rnn returns output and last hidden state\n",
    "        x, hn = self.lstm(x)\n",
    "        \n",
    "        # get a fixed sized hidden representation of the entire sequence\n",
    "        out['hidden'] = x = torch.cat((torch.mean(x, dim=0), torch.max(x, dim=0)[0]), dim=1)\n",
    "        \n",
    "        # classify\n",
    "        out['out'] = self.fc_part(x)# (self.l_out(x), dim=1)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "if use_cuda:\n",
    "    net.cuda(device=1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training we don't want to change the embedding.\n",
    "We therefore need to filter it out from the parameters that we pass to the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embeddings.weight': False,\n",
       " 'proj.weight': True,\n",
       " 'proj.bias': True,\n",
       " 'lstm.weight_ih_l0': True,\n",
       " 'lstm.weight_hh_l0': True,\n",
       " 'lstm.bias_ih_l0': True,\n",
       " 'lstm.bias_hh_l0': True,\n",
       " 'lstm.weight_ih_l0_reverse': True,\n",
       " 'lstm.weight_hh_l0_reverse': True,\n",
       " 'lstm.bias_ih_l0_reverse': True,\n",
       " 'lstm.bias_hh_l0_reverse': True,\n",
       " 'fc_part.0.weight': True,\n",
       " 'fc_part.0.bias': True,\n",
       " 'fc_part.3.weight': True,\n",
       " 'fc_part.3.bias': True,\n",
       " 'fc_part.6.weight': True,\n",
       " 'fc_part.6.bias': True}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which params require grad\n",
    "{p[0]: p[1].requires_grad for p in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# we filter the model's parameters such that we can remove the embedding layer, \n",
    "# which does not have requires_grad\n",
    "optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.01)\n",
    "\n",
    "def accuracy(ys, ts):\n",
    "    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions\n",
    "    correct_prediction = torch.eq(torch.max(ys, 1)[1], ts)\n",
    "    # averaging the one-hot encoded vector\n",
    "    correct_prediction = correct_prediction.float()\n",
    "    return torch.mean(correct_prediction)\n",
    "\n",
    "def construct_sentences(batch):\n",
    "    return [\" \".join([TEXT.vocab.itos[elm] \n",
    "                      for elm in get_numpy(batch.text[:,i])])\n",
    "            for i in range(batch.text.size()[1])]\n",
    "\n",
    "def get_labels(batch):\n",
    "    return [LABEL.vocab.itos[get_numpy(batch.label[i])] for i in range(len(batch.label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to project our hidden embeddings to a visualizable space\n",
    "tsne = TSNE(perplexity=10.0, learning_rate=5.0, n_iter=2000)\n",
    "\n",
    "# index for each label\n",
    "colormap = {1: 'DodgerBlue', 2: 'FireBrick'}\n",
    "# create a tmp source to be updated later\n",
    "validation_set_size = len(validation_set)\n",
    "source = ColumnDataSource(data={'x': np.random.randn(validation_set_size),\n",
    "                                'y': np.random.randn(validation_set_size),\n",
    "                                'colors': ['green']*validation_set_size,\n",
    "                                'sentences': [\"tmp\"]*validation_set_size,\n",
    "                                'labels': [\"unk\"]*validation_set_size})\n",
    "# instance to define hover logic in plot\n",
    "hover = HoverTool(tooltips=[(\"Sentence\", \"@sentences\"), (\"Label\", \"@labels\")])\n",
    "\n",
    "# set up the bokeh figure for later visualizations\n",
    "p = figure(tools=[hover])\n",
    "p.circle(x='x', y='y', fill_color='colors', size=5, line_color=None, source=source)\n",
    "\n",
    "def update_plot(meta, layer, handle):\n",
    "    \"\"\" Update existing plot\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    meta: dict\n",
    "    layer: str\n",
    "    \"\"\"\n",
    "    tsne_acts = tsne.fit_transform(meta[layer])\n",
    "    source.data['x'] = tsne_acts[:,0]\n",
    "    source.data['y'] = tsne_acts[:,1]\n",
    "    source.data['colors'] = [colormap[l] for l in meta['label_idx']]\n",
    "    \n",
    "    source.data['sentences'] = meta['sentences']\n",
    "    source.data['labels'] = meta['labels']\n",
    "    \n",
    "    # this updates the given plot\n",
    "    push_notebook(handle=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM Model\n",
    "\n",
    "**Warning** this might take a while.\n",
    "Go get a cop of coffe, and enjoy the visualizations.\n",
    "\n",
    "Notice that each data point in the plot corresponds to an entire sentence in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"6f5569c5-e4cf-4ef8-ba0e-594bff72522e\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"6f115d37-4243-41d5-b0c9-68fa3e915690\":{\"roots\":{\"references\":[{\"attributes\":{\"formatter\":{\"id\":\"ab0e6825-705e-4067-89a8-17393e389f47\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"8ef05e30-e9d7-475c-823b-38991afd4a09\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"fdfead83-53ba-4de4-9cb7-3af8472970e3\",\"type\":\"BasicTicker\"}},\"id\":\"ce205c8d-d689-4c20-9a66-95c533965a23\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"01a49a07-0ac4-4603-b1de-b3961d718f84\",\"type\":\"Selection\"},{\"attributes\":{\"plot\":{\"id\":\"8ef05e30-e9d7-475c-823b-38991afd4a09\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"fdfead83-53ba-4de4-9cb7-3af8472970e3\",\"type\":\"BasicTicker\"}},\"id\":\"66e591d8-ea10-4af3-92af-22d1d258f177\",\"type\":\"Grid\"},{\"attributes\":{\"plot\":null,\"text\":\"\"},\"id\":\"1627a732-64cf-4665-b7be-3cb78138d8cd\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"0b44c71a-21c2-4d03-8589-3ae31e9fdc54\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"b3d052e9-3f58-4429-b32b-f94d454a89d1\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"ab0e6825-705e-4067-89a8-17393e389f47\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"13ffd00b-93d8-413b-a40f-2f559e9d8bdd\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"34019f74-78f7-4240-abe3-70dae352234f\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"renderers\":\"auto\",\"tooltips\":[[\"Sentence\",\"@sentences\"],[\"Label\",\"@labels\"]]},\"id\":\"4541e02c-6733-4a46-8328-cbd9ec1c462d\",\"type\":\"HoverTool\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"bffb3fd3-c5d9-4041-86b9-6305549148df\",\"type\":\"Circle\"},{\"attributes\":{\"data_source\":{\"id\":\"f4200281-5ff2-4d6a-86ce-05c338def57d\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"88756a44-b108-401c-bfb8-619947a43f30\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"bffb3fd3-c5d9-4041-86b9-6305549148df\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"69a75c95-057f-4363-9aec-f3b8c4887dcb\",\"type\":\"CDSView\"}},\"id\":\"4e45b43c-fcd5-4188-8e9f-c24efdc2aaa0\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"callback\":null},\"id\":\"c76ffc20-332b-4560-bbf6-fd1811a9f2e6\",\"type\":\"DataRange1d\"},{\"attributes\":{\"source\":{\"id\":\"f4200281-5ff2-4d6a-86ce-05c338def57d\",\"type\":\"ColumnDataSource\"}},\"id\":\"69a75c95-057f-4363-9aec-f3b8c4887dcb\",\"type\":\"CDSView\"},{\"attributes\":{\"below\":[{\"id\":\"ce205c8d-d689-4c20-9a66-95c533965a23\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"044acb91-66ae-428d-9d35-b0add7e89574\",\"type\":\"LinearAxis\"}],\"renderers\":[{\"id\":\"ce205c8d-d689-4c20-9a66-95c533965a23\",\"type\":\"LinearAxis\"},{\"id\":\"66e591d8-ea10-4af3-92af-22d1d258f177\",\"type\":\"Grid\"},{\"id\":\"044acb91-66ae-428d-9d35-b0add7e89574\",\"type\":\"LinearAxis\"},{\"id\":\"d1de15c9-fe58-4b89-9312-a6fae64a1da9\",\"type\":\"Grid\"},{\"id\":\"4e45b43c-fcd5-4188-8e9f-c24efdc2aaa0\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1627a732-64cf-4665-b7be-3cb78138d8cd\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"d35f1d6c-5235-4375-b429-a53857a5f616\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"0853575d-9a8d-4c4b-a756-cebe89bcb65e\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"34019f74-78f7-4240-abe3-70dae352234f\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"c76ffc20-332b-4560-bbf6-fd1811a9f2e6\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"0b44c71a-21c2-4d03-8589-3ae31e9fdc54\",\"type\":\"LinearScale\"}},\"id\":\"8ef05e30-e9d7-475c-823b-38991afd4a09\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"callback\":null,\"data\":{\"colors\":[\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\",\"green\"],\"labels\":[\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\",\"unk\"],\"sentences\":[\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\",\"tmp\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[872]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float64\",\"shape\":[872]}},\"selected\":{\"id\":\"01a49a07-0ac4-4603-b1de-b3961d718f84\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"13ffd00b-93d8-413b-a40f-2f559e9d8bdd\",\"type\":\"UnionRenderers\"}},\"id\":\"f4200281-5ff2-4d6a-86ce-05c338def57d\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null},\"id\":\"0853575d-9a8d-4c4b-a756-cebe89bcb65e\",\"type\":\"DataRange1d\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"8ef05e30-e9d7-475c-823b-38991afd4a09\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"89ac2130-2272-4109-ba22-d9718cebd06e\",\"type\":\"BasicTicker\"}},\"id\":\"d1de15c9-fe58-4b89-9312-a6fae64a1da9\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"89ac2130-2272-4109-ba22-d9718cebd06e\",\"type\":\"BasicTicker\"},{\"attributes\":{\"formatter\":{\"id\":\"b3d052e9-3f58-4429-b32b-f94d454a89d1\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"8ef05e30-e9d7-475c-823b-38991afd4a09\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"89ac2130-2272-4109-ba22-d9718cebd06e\",\"type\":\"BasicTicker\"}},\"id\":\"044acb91-66ae-428d-9d35-b0add7e89574\",\"type\":\"LinearAxis\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"4541e02c-6733-4a46-8328-cbd9ec1c462d\",\"type\":\"HoverTool\"}]},\"id\":\"d35f1d6c-5235-4375-b429-a53857a5f616\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"fdfead83-53ba-4de4-9cb7-3af8472970e3\",\"type\":\"BasicTicker\"},{\"attributes\":{\"fill_color\":{\"field\":\"colors\"},\"line_color\":{\"value\":null},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"88756a44-b108-401c-bfb8-619947a43f30\",\"type\":\"Circle\"}],\"root_ids\":[\"8ef05e30-e9d7-475c-823b-38991afd4a09\"]},\"title\":\"Bokeh Application\",\"version\":\"0.13.0\"}};\n",
       "  var render_items = [{\"docid\":\"6f115d37-4243-41d5-b0c9-68fa3e915690\",\"notebook_comms_target\":\"cc6cc737-1b8d-4238-9625-fd87ea6073da\",\"roots\":{\"8ef05e30-e9d7-475c-823b-38991afd4a09\":\"6f5569c5-e4cf-4ef8-ba0e-594bff72522e\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "8ef05e30-e9d7-475c-823b-38991afd4a09"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zhome/9d/d/98006/Documents/02456-Deep-learning/lib/python3.6/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### EVAL loss: 1.11 accs: 0.00\n",
      "train, it: 0 loss: 1.11 accs: 0.02\n",
      "train, it: 500 loss: 1.06 accs: 0.52\n",
      "### EVAL loss: 1.00 accs: 0.51\n",
      "train, it: 1000 loss: 1.00 accs: 0.57\n",
      "train, it: 1500 loss: 0.97 accs: 0.57\n",
      "### EVAL loss: 0.98 accs: 0.51\n",
      "train, it: 2000 loss: 0.96 accs: 0.57\n",
      "train, it: 2500 loss: 0.96 accs: 0.57\n",
      "### EVAL loss: 0.98 accs: 0.51\n",
      "train, it: 3000 loss: 0.95 accs: 0.57\n",
      "train, it: 3500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 4000 loss: 0.95 accs: 0.57\n",
      "train, it: 4500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 5000 loss: 0.95 accs: 0.57\n",
      "train, it: 5500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 6000 loss: 0.95 accs: 0.57\n",
      "train, it: 6500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 7000 loss: 0.95 accs: 0.57\n",
      "train, it: 7500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 8000 loss: 0.95 accs: 0.57\n",
      "train, it: 8500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 9000 loss: 0.95 accs: 0.57\n",
      "train, it: 9500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 10000 loss: 0.95 accs: 0.57\n",
      "train, it: 10500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 11000 loss: 0.95 accs: 0.57\n",
      "train, it: 11500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 12000 loss: 0.95 accs: 0.57\n",
      "train, it: 12500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 13000 loss: 0.95 accs: 0.57\n",
      "train, it: 13500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 14000 loss: 0.95 accs: 0.57\n",
      "train, it: 14500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 15000 loss: 0.95 accs: 0.57\n",
      "train, it: 15500 loss: 0.95 accs: 0.57\n",
      "### EVAL loss: 0.97 accs: 0.51\n",
      "train, it: 16000 loss: 0.95 accs: 0.57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-343f6a304ac6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-04433aca1165>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# rnn returns output and last hidden state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# get a fixed sized hidden representation of the entire sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mnexth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvariable_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_directions\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mnext_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mall_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, hidden, weight, batch_sizes)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreverse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0;31m# hack to handle LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mLSTMCell\u001b[0;34m(input, hidden, w_ih, w_hh, b_ih, b_hh)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mgates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_ih\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_hh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_hh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mingate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforgetgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcellgate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_iter = 25000\n",
    "eval_every = 1000\n",
    "log_every = 500\n",
    "tsne_every = eval_every * 5\n",
    "\n",
    "# will be updated while iterating\n",
    "tsne_plot = show(p, notebook_handle=True)\n",
    "\n",
    "train_loss, train_accs = [], []\n",
    "\n",
    "net.train()\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if i % eval_every == 0:\n",
    "        net.eval()\n",
    "        val_losses, val_accs, val_lengths = 0, 0, 0\n",
    "        val_meta = {'label_idx': [], 'sentences': [], 'labels': []}\n",
    "        for val_batch in val_iter:\n",
    "            output = net(val_batch.text)\n",
    "            # batches sizes might vary, which is why we cannot just mean the batch's loss\n",
    "            # we multiply the loss and accuracies with the batch's size,\n",
    "            # to later divide by the total size\n",
    "            val_losses += criterion(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_accs += accuracy(output['out'], val_batch.label) * val_batch.batch_size\n",
    "            val_lengths += val_batch.batch_size\n",
    "            \n",
    "            for key, _val in output.items():\n",
    "                if key not in val_meta:\n",
    "                    val_meta[key] = []\n",
    "                val_meta[key].append(get_numpy(_val)) \n",
    "            val_meta['label_idx'].append(get_numpy(val_batch.label))\n",
    "            val_meta['sentences'].append(construct_sentences(val_batch))\n",
    "            val_meta['labels'].append(get_labels(val_batch))\n",
    "        \n",
    "        for key, _val in val_meta.items():\n",
    "            val_meta[key] = np.concatenate(_val)\n",
    "        \n",
    "        # divide by the total accumulated batch sizes\n",
    "        val_losses /= val_lengths\n",
    "        val_accs /= val_lengths\n",
    "        \n",
    "        print(\"### EVAL loss: {:.2f} accs: {:.2f}\".format(get_numpy(val_losses),\n",
    "                                                          get_numpy(val_accs)))\n",
    "        if i % tsne_every == 0:\n",
    "            update_plot(val_meta, 'hidden', tsne_plot)\n",
    "        \n",
    "        net.train()\n",
    "    \n",
    "    output = net(batch.text)\n",
    "    batch_loss = criterion(output['out'], batch.label)\n",
    "    \n",
    "    train_loss.append(get_numpy(batch_loss))\n",
    "    train_accs.append(get_numpy(accuracy(output['out'], batch.label)))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % log_every == 0:        \n",
    "        print(\"train, it: {} loss: {:.2f} accs: {:.2f}\".format(i, \n",
    "                                                               np.mean(train_loss), \n",
    "                                                               np.mean(train_accs)))\n",
    "        # reset\n",
    "        train_loss, train_accs = [], []\n",
    "        \n",
    "    \n",
    "    if max_iter < i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/zhome/9d/d/98006/Documents/02456-Deep-learning/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m(1407)\u001b[0;36mnll_loss\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1405 \u001b[0;31m                         .format(input.size(0), target.size(0)))\n",
      "\u001b[0m\u001b[0;32m   1406 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1407 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1408 \u001b[0;31m    \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1409 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> cur_target\n",
      "*** NameError: name 'cur_target' is not defined\n",
      "ipdb> target\n",
      "tensor([1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1,\n",
      "        2, 2, 2, 1, 2, 2, 2, 1])\n",
      "ipdb> target.size()\n",
      "torch.Size([128])\n",
      "ipdb> input.size()\n",
      "torch.Size([128, 1])\n",
      "ipdb> quit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above vanilla model should achieve below 80% accuracy in evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments\n",
    "\n",
    "## Assignment 1\n",
    "\n",
    "Upgrade the model such that it is equivalent to the model presented in [Johansen & Socher](https://arxiv.org/abs/1712.05483).\n",
    "See figure A3 for an illustration.\n",
    "\n",
    "- Note, batch and sequence dimensions are flipped\n",
    "- A *projection layer* is a fully connected layer, which does not necessarily have a non-linearity\n",
    "- Notice, that you also need to update the optimizer\n",
    "\n",
    "> **Goal** you should see evaluation acccuracy around 86%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional reading material and lab\n",
    "\n",
    "- follow [pytorch's seq2seq lab](http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html) for a complete implementation of a seq2seq model\n",
    "\n",
    "also, you might want to read the following articles (which are also mentioned in the above lab):\n",
    "\n",
    "- [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)\n",
    "- [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)\n",
    "- [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
