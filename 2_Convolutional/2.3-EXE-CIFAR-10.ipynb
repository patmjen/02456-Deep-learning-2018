{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced from https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "In thins notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.\n",
    "\n",
    "It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’.\n",
    "The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.\n",
    "\n",
    "![cifar10](../static_files/cifar10.png)\n",
    "\n",
    "\n",
    "In order to train a classifier the following steps needs to be performed:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolutional Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "We will help you along the way.\n",
    "We indicate the places you need to modify the code with `# Your code here!`.\n",
    "It is however a good idea to read the entire assignment before you begin coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading and normalizing CIFAR10\n",
    "\n",
    "Using ``torchvision``, it’s extremely easy to load CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1]\n",
    "\n",
    "**NB** Modify the code below to only use a small part of the dataset if your computer is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Setup device to compute on\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print('Device is:', device)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                          (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "print()\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "used_categories = range(len(classes))\n",
    "\n",
    "## USE CODE BELOW IF YOUR COMPUTER IS TOO SLOW\n",
    "reduce_dataset = False\n",
    "if reduce_dataset:\n",
    "    used_categories = (3, 5) # cats and dogs\n",
    "\n",
    "    classes = [classes[i] for i in used_categories]\n",
    "    new_train_data = []\n",
    "    new_train_labels = []\n",
    "\n",
    "    new_test_data = []\n",
    "    new_test_labels = []\n",
    "    for i, t in enumerate(used_categories):\n",
    "        new_train_data.append(trainset.train_data[np.where(np.array(trainset.train_labels) == t)])\n",
    "        new_train_labels += [i for _ in range(new_train_data[-1].shape[0])]\n",
    "\n",
    "        new_test_data.append(testset.test_data[np.where(np.array(testset.test_labels) == t)])\n",
    "        new_test_labels += [i for _ in range(new_test_data[-1].shape[0])]\n",
    "\n",
    "    new_train_data = np.concatenate(new_train_data, 0)\n",
    "    trainset.train_data = new_train_data\n",
    "    trainset.train_labels = new_train_labels\n",
    "\n",
    "    new_test_data = np.concatenate(new_test_data, 0)\n",
    "    testset.test_data = new_test_data\n",
    "    testset.test_labels = new_test_labels\n",
    "\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=124,\n",
    "                                          shuffle=True, num_workers=2, pin_memory=(device.type=='cuda'))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2, pin_memory=(device.type=='cuda'))\n",
    "train_data_iter = iter(trainloader)\n",
    "test_data_iter = iter(testloader)\n",
    "print('used classes:', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data\")\n",
    "print(trainset.train_data.shape)\n",
    "print(len(trainset.train_labels))\n",
    "print()\n",
    "\n",
    "print(\"Test data\")\n",
    "print(testset.test_data.shape)\n",
    "print(len(testset.test_labels))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show some of the training images, for fun.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple time to see more samples\n",
    "\n",
    "def imshow(img):\n",
    "    \"\"\" show an image \"\"\"\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "images, labels = train_data_iter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a Convolutional Neural Network\n",
    "\n",
    "**Assignment 1:** Define a convolutional neural network. \n",
    "You may use the code from previous notebooks.\n",
    "We suggest that you start with a small network, and make sure that everything is working.\n",
    "Once you can train successfully come back and improve the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "width = 32\n",
    "height = 32\n",
    "channels = 3\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        self.linear_in = 64 * 8 * 8 # Number of features when we finish the conv. part\n",
    "        \n",
    "        # We split up the conv. part and the fully connected part so can make a view of x\n",
    "        # before feeding it to the fully connected part\n",
    "        \n",
    "        # Setup conv. part of the network\n",
    "        self.conv_part = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=channels,\n",
    "                out_channels=64,\n",
    "                kernel_size=7,\n",
    "                padding=3),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=5,\n",
    "                padding=2),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=128,\n",
    "                kernel_size=7,\n",
    "                padding=3),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(\n",
    "                in_channels=128,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                padding=2),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # Setup fully connected part of the network\n",
    "        self.fc_part = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(\n",
    "                in_features=self.linear_in,\n",
    "                out_features=100),\n",
    "            nn.BatchNorm1d(num_features=100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(\n",
    "                in_features=100,\n",
    "                out_features=self.num_classes),\n",
    "            nn.BatchNorm1d(num_features=self.num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_part(x)  # Do conv. part\n",
    "        x = x.view(-1, self.linear_in) # Transform to linear input\n",
    "        return self.fc_part(x) # Do fully connected part\n",
    "    \n",
    "net = Net(len(used_categories)).to(device)\n",
    "print(net)\n",
    "for param in net.parameters():\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test forward pass on dummy data\n",
    "x = np.random.normal(0,1, (5, channels, height, width)).astype('float32')\n",
    "x = Variable(torch.from_numpy(x))\n",
    "x = x.to(device)\n",
    "output = net(x)\n",
    "print(output.size())\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define a Loss function and optimizer\n",
    "\n",
    "**Assignment 2:** Implement the criterion and optimizer. \n",
    "We suggest Classification Cross-Entropy loss and SGD with momentum.\n",
    "You might need to experiment a bit with the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device) # Since we are doing a classification problem\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the network\n",
    "\n",
    "**Assignment 3:** Finish the training loop below. \n",
    "Start by using a small number of epochs (e.g. 3).\n",
    "Even with a low number of epochs you should be able to see results that are better than chance.\n",
    "When everything is working increase the number of epochs to find out how good your network really is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "num_epoch = 35\n",
    "\n",
    "losses = []\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = torch.zeros(1, requires_grad=False).to(device)\n",
    "    epoch_loss = torch.zeros(1, requires_grad=False).to(device)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs = Variable(inputs.to(device, non_blocking=True))\n",
    "        labels = Variable(labels.to(device, non_blocking=True))\n",
    "\n",
    "        net.train()\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.detach() # Detech loss from its graph\n",
    "        epoch_loss += loss.detach()\n",
    "        #if i % 100 == 99:    # print every 100 mini-batches\n",
    "        #    print('[%d, %5d] loss: %.3f' %\n",
    "        #          (epoch + 1, i + 1, running_loss / 100))\n",
    "        #    running_loss = 0.0\n",
    "    \n",
    "    print('epoch: {}, loss: {}'.format(epoch, epoch_loss.item()))\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "net.eval()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test the network on the test data\n",
    "\n",
    "Now we need to check if the network has learnt anything at all.\n",
    "We will check this by predicting the class label that the neural network outputs, and checking it against the ground truth.\n",
    "If the prediction is correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = test_data_iter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "plt.show()\n",
    "\n",
    "print('GroundTruth:  ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted:    ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the network performs on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct = 0\n",
    "test_total = 0\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "net.eval()\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    test_total += labels.size(0)\n",
    "    test_correct += (predicted == labels).sum()\n",
    "\n",
    "for data in trainloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    train_total += labels.size(0)\n",
    "    train_correct += (predicted == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\n",
    "    testset.test_data.shape[0], 100 * test_correct / test_total))\n",
    "\n",
    "print('Accuracy of the network on the {} training images: {:4.2f} %'.format(\n",
    "    trainset.train_data.shape[0], 100 * train_correct / train_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully the network is better than chance, which is $\\frac{1}{\\text{number of classes}}$ accuracy (randomly picking\n",
    "a class).\n",
    "\n",
    "\n",
    "We can also examine which class the network found the most difficult (makes more sense if you have many clases):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_total = list(0. for i in range(len(classes)))\n",
    "class_correct = list(0. for i in range(len(classes)))\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    \n",
    "    for i in range(len(c)):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i].cpu().numpy()\n",
    "        class_total[label] += 1\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print('Accuracy of {:5s} : {:5.2f} %'.format(\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assignment 4:** \n",
    "1. Go back and improve performance of the network. \n",
    " * If you are using all 10 classes you should get a test accuracy above 55%, but see how much further you can get it!\n",
    " * If you are using only 2 classes (e.g. cat and dog) you should get a test accuracy above 60%, but see how much further you can get it!\n",
    "\n",
    "2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.\n",
    "Did anything surprise you during the exercise?\n",
    "\n",
    "3. Write down key lessons/insights you got (if any) during this exercise.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "For all my networks I used log-softmax for the final activation. This was inspired by the MNIST cluttered demo. The network parameters are given in the cell below. I used ADAM as my optimizer.\n",
    "\n",
    "First, I made a simple network with 1 conv. layer, 1 maxpool layer, 1 ReLU layer, and then 2 fully connected layers, with ReLU activation between them. Training ran for 3 epocs. It gave a test accuracy of ~60%.\n",
    "\n",
    "Next, I added an extra set of conv.- and pooling layers, as well as batch normalization. I also added a weight decay of 1e-4, and trained for 5 epocs, and set the batch size to 64. This gave a test accuracy of ~70% and a training accuracy of ~82%. When I looked at the losses it seemed like more training would be beneficial.\n",
    "\n",
    "Next, I wanted to confirm that net 2 was better than net 1. So I retrained the net 1 the same way I trained net 2. This gave a test accuracy of 64% and a training accuracy of 75%. So net 2 seems better.\n",
    "\n",
    "Next, I trained net 2 for 50 epocs. This gave test accuracy of 66% and a training accuracy of 98%, so the network is overfitting. Thus, I upped the regularization.\n",
    "\n",
    "Next i experimented with different ordering of the layers, adding more layers, different batch sizes, and different hyperparameters. I tried to only change one thing at a time, so I could hopefully pinpoint what helped. The network I ended up with was net 3, shown below. it gave a test accuracy of 75% and a training accuracy of 98%. Looking at the loss plot, it seems like there may have been some benefit to training for longer, but I this is not certain.\n",
    "\n",
    "My key lessons / insights were:\n",
    "\n",
    "* It seems like a larger batch size leads to better run times, but does not seem to affect accuracy that much.\n",
    "* It is **very** important to have good regularization, otherwise you will overfit and lose validation acc.\n",
    "* Larger networks need to train longer than smaller, likely due to the large number of parameters.\n",
    "* It seems like it was generally easier to train for \"things\" such ships, than the mammals. I think this could have something to do with the image backgrounds, since e.g. an image of a ship will likely also have a large blue area in the bottom of the picture, which might be easier to learn. \n",
    "* Generally, cats and dogs seem to cause the most trouble. However, of the included classes I would also say that these two are the most similar, and would tend to have similar backgrounds. Thus, this is not entirely unexpected."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Net 1\n",
    "=====\n",
    "Net(\n",
    "  (conv_part): Sequential(\n",
    "    (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
    "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (2): ReLU(inplace)\n",
    "  )\n",
    "  (fc_part): Sequential(\n",
    "    (0): Linear(in_features=4096, out_features=50, bias=True)\n",
    "    (1): ReLU(inplace)\n",
    "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
    "    (3): LogSoftmax()\n",
    "  )\n",
    ")\n",
    "\n",
    "Net 2\n",
    "=====\n",
    "Net(\n",
    "  (conv_part): Sequential(\n",
    "    (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
    "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (2): ReLU(inplace)\n",
    "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (6): ReLU(inplace)\n",
    "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    "  (fc_part): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=50, bias=True)\n",
    "    (1): ReLU(inplace)\n",
    "    (2): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): Linear(in_features=50, out_features=10, bias=True)\n",
    "    (4): LogSoftmax()\n",
    "  )\n",
    ")\n",
    "\n",
    "Net 3\n",
    "=====\n",
    "Net(\n",
    "  (conv_part): Sequential(\n",
    "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU(inplace)\n",
    "    (3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (5): ReLU(inplace)\n",
    "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (7): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
    "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (9): ReLU(inplace)\n",
    "    (10): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (12): ReLU(inplace)\n",
    "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (fc_part): Sequential(\n",
    "    (0): Dropout(p=0.2)\n",
    "    (1): Linear(in_features=4096, out_features=100, bias=True)\n",
    "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (3): ReLU(inplace)\n",
    "    (4): Dropout(p=0.2)\n",
    "    (5): Linear(in_features=100, out_features=10, bias=True)\n",
    "    (6): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (7): LogSoftmax()\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on GPU\n",
    "\n",
    "**Optional Assignment:**\n",
    "If you have a GPU we suggest that you try and rewrite the code above to run on the GPU\n",
    "___\n",
    "\n",
    "Just like how you transfer a Tensor on to the GPU, you transfer the neural net onto the GPU.\n",
    "This will recursively go over all modules and convert their parameters and buffers to CUDA tensors:\n",
    "\n",
    "```\n",
    "    net.cuda()\n",
    "```\n",
    "\n",
    "Remember that you will have to send the inputs and targets at every step to the GPU too:\n",
    "\n",
    "```\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "```\n",
    "\n",
    "Why dont I notice MASSIVE speedup compared to CPU? \n",
    "Because your network is realllly small.\n",
    "\n",
    "**Exercise:** Try increasing the width of your network (argument 2 of\n",
    "the first ``nn.Conv2d``, and argument 1 of the second ``nn.Conv2d`` –\n",
    "they need to be the same number), see what kind of speedup you get.\n",
    "\n",
    "**Goals achieved**:\n",
    "\n",
    "- Understanding PyTorch's Tensor library and neural networks at a high level.\n",
    "- Train a small neural network to classify images\n",
    "\n",
    "**Answer**:\n",
    "\n",
    "I have added support for GPU in the following ways:\n",
    "* I move my neural net to the GPU.\n",
    "* I move my loss function to the GPU.\n",
    "* I move my training batches to the GPU when training, so I train on the GPU.\n",
    "* I also move batches to the GPU when evaluating.\n",
    "* I move loss values back to the host, so I can store them.\n",
    "* I have added the `pin_memory=(device.type=='cuda')` argument to the data loader, so it loads the batches into pinned memory (if the device is set to GPU). This should make host to GPU transfers faster, but I did not really see a speedup.\n",
    "* I have added the `non_blocking=True` argument, when I transfer training batches to the GPU. Again, this should cause a speedup as it would allow the GPU to also run code while transfering data. However, I did not see an effect.\n",
    "\n",
    "It seems like most of the time while training is spent on tranferring data to the GPU. Besides what I have tried, I do not know how speed it up. However, I **did** notice a speedup compared to the CPU version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Michael Nielsen book exercise of own choice\n",
    "\n",
    "**Assignment 5:** Pick an exercise of own choice from [Michael Nielsens book](http://neuralnetworksanddeeplearning.com/)\n",
    "\n",
    "**Answer:** I chose the exercise in chapter 3:\n",
    ">Verify that $\\sigma'(z) = \\sigma(z)(1 - \\sigma(z))$.\n",
    "\n",
    "We know that \n",
    "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "Thus, \n",
    "$$\\sigma'(z) = \\frac{e^{-z}}{(1 + e^{-z})^2}.$$\n",
    "Insertion gives us that\n",
    "$$\n",
    "\\sigma(z)\\left(1 - \\sigma(z)\\right) = \\frac{1}{1 + e^{-z}}\\left( 1 - \\frac{1}{1 + e^{-z}} \\right) = \\frac{1}{1 + e^{-z}}\\left( \\frac{e^{-z}}{1 + e^{-z}} \\right) = \\frac{e^{-z}}{(1 + e^{-z})^2} = \\sigma'(z),\n",
    "$$\n",
    "which concludes the proof.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
